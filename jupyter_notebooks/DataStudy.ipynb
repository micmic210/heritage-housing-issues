{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Study Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Answer Business Requirement 1:\n",
        "The client is interested in discovering how house attributes correlate with the sale price.\n",
        "- Generate correlation & visualization code for the Streamlit dashboard.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousePrices.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers business requirement 1 and can be used to build the Streamlit App.\n",
        "* Creating plots to see correlation for the selected variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We change the working directory to the parent of the current one using os.path.dirname() and os.chdir()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"outputs/datasets/cleaned/HousePricesCleaned.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start with a data profiling report to better understand the dataset. This helps us review variable types, distributions, missing values, and how each variable may relate to the target.\n",
        "\n",
        "We use the ydata-profiling library to generate this report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The profiling report shows:\n",
        "- Nine features contain missing values.\n",
        "- EnclosedPorch and WoodDeckSF have the highest missing ratesâ€”90.7% and 89.4%, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our dataset includes four categorical variables stored as objects. We need to encode them to calculate correlation coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(\n",
        "    variables=df.columns[df.dtypes == \"object\"].to_list(), drop_last=False\n",
        ")\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- After encoding, the dataset expands to 37 columns, with each category represented as a separate binary column (0 or 1).\n",
        "- Next, we define functions to calculate correlation values, generate heatmaps, and display them.\n",
        "- Each heatmap is saved to the docs directory for use in project documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import ppscore as pps\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  \"\"\"\n",
        "  Function to create heatmap using correlations.\n",
        "  \"\"\"\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "     # Save heatmaps to docs folder\n",
        "    if df.name == \"corr_spearman\":\n",
        "      plt.savefig(f'docs/plots/heatmap_corr_spearman.png', bbox_inches='tight')\n",
        "    else:\n",
        "      plt.savefig(f'docs/plots/heatmap_corr_pearson.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    \"\"\"\n",
        "    Function to create heatmap using pps.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      # Save heatmap to docs folder\n",
        "      plt.savefig(f'docs/plots/heatmap_pps.png', bbox_inches='tight')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  \"\"\"\n",
        "  Function to calculate correlations and pps.\n",
        "  \"\"\"\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_spearman.name = 'corr_spearman'\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "  df_corr_pearson.name = 'corr_pearson'\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "  \"\"\"\n",
        "  Function to display the correlations and pps.\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(\n",
        "    df_corr_pearson=df_corr_pearson,\n",
        "    df_corr_spearman=df_corr_spearman,\n",
        "    pps_matrix=pps_matrix,\n",
        "    CorrThreshold=0.4,\n",
        "    PPS_Threshold=0.2,\n",
        "    figsize=(12, 10),\n",
        "    font_annot=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = (\n",
        "    df_ohe.corr(method=\"spearman\")[\"SalePrice\"]\n",
        "    .sort_values(key=abs, ascending=False)[1:]\n",
        "    .head(10)\n",
        ")\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = (\n",
        "    df_ohe.corr(method=\"pearson\")[\"SalePrice\"]\n",
        "    .sort_values(key=abs, ascending=False)[1:]\n",
        "    .head(10)\n",
        ")\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 10\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = [\n",
        "    \"1stFlrSF\",\n",
        "    \"GarageArea\",\n",
        "    \"GrLivArea\",\n",
        "    \"KitchenQual\",\n",
        "    \"MasVnrArea\",\n",
        "    \"OpenPorchSF\",\n",
        "    \"OverallQual\",\n",
        "    \"TotalBsmtSF\",\n",
        "    \"YearBuilt\",\n",
        "    \"YearRemodAdd\",\n",
        "]\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create EDA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run EDA using features moderately or strongly correlated with SalePrice, creating a DataFrame that includes the target for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df[vars_to_study + [\"SalePrice\"]]\n",
        "df_eda.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Target Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distribution of Sales Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "target_var = \"SalePrice\"\n",
        "time = [\"YearBuilt\", \"YearRemodAdd\"]\n",
        "\n",
        "\n",
        "def plot_target_hist(df, target_var):\n",
        "    \"\"\"\n",
        "    Function to plot a histogram of the target and\n",
        "    save the figure to folder.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.histplot(data=df, x=target_var, kde=True)\n",
        "    plt.title(f\"Distribution of {target_var}\", fontsize=20)\n",
        "    plt.savefig(f\"docs/plots/hist_plot_{target_var}.png\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_target_hist(df, target_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bivariate plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To address business requirement 1, we plot SalePrice against key numerical and categorical features to explore their relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lm(df, col, target_var):\n",
        "    \"\"\"\n",
        "    Function to create linear regression plots of the target and\n",
        "    features with continuous values.\n",
        "    It saves each figure to folder.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.lmplot(data=df, x=col, y=target_var, ci=None)\n",
        "    plt.title(f\"{col}\", fontsize=20)\n",
        "    plt.savefig(f\"docs/plots/lm_plot_price_by_{col}.png\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_line(df, col, target_var):\n",
        "    \"\"\"\n",
        "    Function to create a line plot of the target and\n",
        "    time variables (years).\n",
        "    It saves each figure to folder.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.lineplot(data=df, x=col, y=target_var)\n",
        "    plt.title(f\"{col}\", fontsize=20)\n",
        "    plt.savefig(f\"docs/plots/line_plot_price_by_{col}.png\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_box(df, col, target_var):\n",
        "    \"\"\"\n",
        "    Function to create a box plot of the target and\n",
        "    categorical variables.\n",
        "    It saves each figure to folder.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(data=df, x=col, y=target_var)\n",
        "    plt.title(f\"{col}\", fontsize=20)\n",
        "    plt.savefig(f\"docs/plots/box_plot_price_by_{col}\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for col in vars_to_study:\n",
        "    if len(df_eda[col].unique()) <= 10:\n",
        "        plot_box(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")\n",
        "    else:\n",
        "        if col in time:\n",
        "            plot_line(df_eda, col, target_var)\n",
        "            print(\"\\n\\n\")\n",
        "        else:\n",
        "            plot_lm(df_eda, col, target_var)\n",
        "            print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plots show that higher feature values generally align with higher sale prices. However, outliers are present, similar to what we saw in the target variable.\n",
        "Weâ€™ll address these outliers during feature engineering to prepare the data for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and the Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Summary**\n",
        "\n",
        "The correlation analysis confirms:\n",
        "- 'OverallQual', 'GrLivArea', and 'YearBuilt' show strong correlation with 'SalePrice'.\n",
        "- Variables related to size (e.g., 1stFlrSF, TotalBsmtSF) and condition (e.g., OverallQual) are most predictive.\n",
        "- From 1980 onwards, newer homes see significant price increases.\n",
        "\n",
        "**Next Step**:\n",
        "Proceed to Feature Engineering notebook.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
