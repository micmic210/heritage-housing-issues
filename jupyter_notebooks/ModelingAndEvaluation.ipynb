{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modeling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Answer Business Requirement 2: train regression models to predict house sale prices\n",
        "- Compare baseline algorithms with cross-validation\n",
        "- Tune the best candidate model with GridSearchCV\n",
        "- Evaluate final model performance (learning curves, residuals)\n",
        "- Inspect feature importances (permutation and tree-based)\n",
        "- Generate predictions for Lydia’s four inherited houses\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- outputs/datasets/feature_engineered/Train_FE.csv\n",
        "- outputs/datasets/feature_engineered/Test_FE.csv\n",
        "- outputs/datasets/collection/InheritedHouses.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Model comparison table (CV RMSE, R², MAE)\n",
        "- Hyperparameter search results summary\n",
        "- Final tuned pipeline saved to outputs/ml_pipeline/predict_price/predict_price_pipeline_v1.pkl\n",
        "- Feature importance plots under docs/plots\n",
        "- Learning curve, residuals, actual vs predicted plots under docs/plots\n",
        "- Predicted sale prices for inherited homes\n",
        "Business‑requirement pass/fail statement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# set project root\n",
        "dir_path = os.getcwd()\n",
        "os.chdir(os.path.dirname(dir_path))\n",
        "print(\"Working dir:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries and Suppress Warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    cross_val_score,\n",
        "    learning_curve,\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import uniform, randint\n",
        "import joblib\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Load Feature‑Engineered Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"outputs/datasets/feature_engineered/Train_FE.csv\")\n",
        "df_test = pd.read_csv(\"outputs/datasets/feature_engineered/Test_FE.csv\")\n",
        "print(\"Train FE shape:\", df_train.shape)\n",
        "print(\"Test  FE shape:\", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = \"SalePrice\"\n",
        "X_train = df_train.drop(columns=target)\n",
        "y_train = df_train[target]\n",
        "X_test = df_test.drop(columns=target)\n",
        "y_test = df_test[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model Comparison (5‑fold CV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models to compare\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
        "}\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([(\"model\", model)])\n",
        "    # CV metrics\n",
        "    rmse = -cross_val_score(\n",
        "        pipe, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\"\n",
        "    )\n",
        "    r2 = cross_val_score(pipe, X_train, y_train, cv=5, scoring=\"r2\")\n",
        "    mae = -cross_val_score(\n",
        "        pipe, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\"\n",
        "    )\n",
        "    results.append(\n",
        "        {\n",
        "            \"Model\": name,\n",
        "            \"RMSE_Mean\": rmse.mean(),\n",
        "            \"R2_Mean\": r2.mean(),\n",
        "            \"MAE_Mean\": mae.mean(),\n",
        "        }\n",
        "    )\n",
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(results).sort_values(\"RMSE_Mean\")\n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comment: RandomForest shows lowest CV RMSE, so we select it for tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Search (RandomizedSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use FE pipeline if integrated, here we tune model only\n",
        "best_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define 6 hyperparameters with multiple options\n",
        "dist = {\n",
        "    \"model__n_estimators\": [100, 200, 300],\n",
        "    \"model__max_depth\": [None, 10, 20],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "    \"model__min_samples_leaf\": [1, 2, 4],\n",
        "    \"model__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "    \"model__bootstrap\": [True, False],\n",
        "}\n",
        "\n",
        "# Pipeline wrapping the model\n",
        "temp_pipe = Pipeline([(\"model\", best_model)])\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rand_search = RandomizedSearchCV(\n",
        "    estimator=temp_pipe,\n",
        "    param_distributions=dist,\n",
        "    n_iter=50,\n",
        "    cv=3,\n",
        "    scoring=\"neg_root_mean_squared_error\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    return_train_score=True,\n",
        ")\n",
        "rand_search.fit(X_train, y_train)\n",
        "print(\"Best params:\", rand_search.best_params_)\n",
        "\n",
        "# Show top 10 search results\n",
        "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
        "display(\n",
        "    cv_results[[\"params\", \"mean_test_score\", \"std_test_score\"]]\n",
        "    .sort_values(\"mean_test_score\", ascending=False)\n",
        "    .head(10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comment: RandomizedSearchCV limits compute while exploring 6 parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Final Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function for metrics\n",
        "def evaluate_performance(pipe, X_tr, y_tr, X_te, y_te):\n",
        "    \"\"\"\n",
        "    Print RMSE, R², MAE for train and test sets.\n",
        "    \"\"\"\n",
        "    for label, X, y in [(\"Train\", X_tr, y_tr), (\"Test\", X_te, y_te)]:\n",
        "        preds = pipe.predict(X)\n",
        "        rmse = np.sqrt(mean_squared_error(y, preds))\n",
        "        r2 = r2_score(y, preds)\n",
        "        mae = mean_absolute_error(y, preds)\n",
        "        print(f\"{label} RMSE: {rmse:.2f}, R2: {r2:.3f}, MAE: {mae:.2f}\")\n",
        "\n",
        "\n",
        "final_pipe = rand_search.best_estimator_\n",
        "evaluate_performance(final_pipe, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actual vs Predicted Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test, final_pipe.predict(X_test), alpha=0.6)\n",
        "# 45-degree line\n",
        "ymin, ymax = y_test.min(), y_test.max()\n",
        "plt.plot([ymin, ymax], [ymin, ymax], \"r--\")\n",
        "plt.xlabel(\"Actual SalePrice\")\n",
        "plt.ylabel(\"Predicted SalePrice\")\n",
        "plt.title(\"Actual vs Predicted\")\n",
        "plt.savefig(\"docs/plots/actual_vs_predicted.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Curve & Residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    final_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"neg_root_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "    n_jobs=-1,\n",
        ")\n",
        "train_rmse = -train_scores\n",
        "test_rmse = -test_scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_sizes, train_rmse.mean(axis=1), \"o-\", label=\"Train RMSE\")\n",
        "plt.plot(train_sizes, test_rmse.mean(axis=1), \"o-\", label=\"CV RMSE\")\n",
        "plt.xlabel(\"Training Examples\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.legend()\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.savefig(\"docs/plots/learning_curve.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Residuals\n",
        "residuals = y_test - final_pipe.predict(X_test)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title(\"Residual Distribution (Test)\")\n",
        "plt.savefig(\"docs/plots/residuals.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare tree-based importances and permutation importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tree-based importances\n",
        "feat_names = X_train.columns\n",
        "if hasattr(final_pipe.named_steps[\"model\"], \"feature_importances_\"):\n",
        "    tree_imp = final_pipe.named_steps[\"model\"].feature_importances_\n",
        "    df_tree = pd.Series(tree_imp, index=feat_names).nlargest(20)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x=df_tree.values, y=df_tree.index)\n",
        "    plt.title(\"Top 20 Tree-based Feature Importances\")\n",
        "    plt.savefig(\"docs/plots/feature_importances_tree.png\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "# Permutation importances\n",
        "perm = permutation_importance(\n",
        "    final_pipe, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
        ")\n",
        "df_perm = pd.Series(perm.importances_mean, index=feat_names).nlargest(20)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=df_perm.values, y=df_perm.index)\n",
        "plt.title(\"Top 20 Permutation Importances\")\n",
        "plt.savefig(\"docs/plots/feature_importances_perm.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Inherited Houses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inherited = pd.read_csv(\"outputs/datasets/collection/InheritedHouses.csv\")\n",
        "# Align columns\n",
        "for col in X_train.columns:\n",
        "    if col not in inherited:\n",
        "        inherited[col] = np.nan\n",
        "inherited = inherited[X_train.columns]\n",
        "# Predict\n",
        "df_pred = final_pipe.predict(inherited)\n",
        "for i, p in enumerate(df_pred, 1):\n",
        "    print(f\"House {i}: ${p:,.0f}\")\n",
        "print(f\"Total estimated value: ${df_pred.sum():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business‑Requirement Pass/Fail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tuned RandomForest with optimized hyperparameters achieves Test R² = {r2_score(y_test, final_pipe.predict(X_test)):.3f},\n",
        "which exceeds the business requirement of R² ≥ 0.80. The average error MAE = {mean_absolute_error(y_test, final_pipe.predict(X_test)):.2f}\n",
        "is within 10% of the average sale price (≈{y_test.mean():.0f}), therefore the model meets the business requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Summary**:\n",
        "- We compared several regression models and found RandomForest performed best. Using RandomizedSearchCV, we tuned six key hyperparameters and evaluated the final pipeline with RMSE, R², MAE, learning curves, residuals, and actual vs. predicted plots.\n",
        "- We also reviewed feature importances and generated sale‐price predictions for Lydia’s four inherited homes, meeting the business requirement of R² ≥ 0.80.\n",
        "\n",
        "**Next Step:** \n",
        "- Plug the saved pipeline (predict_price_pipeline_v1.pkl) into the Streamlit app.\n",
        "- Add user inputs (sliders/dropdowns) for live price predictions.\n",
        "- Plan regular retraining or tuning with new data to keep the model accurate."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
