{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modeling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Answer Business Requirement 2: train regression models to predict house sale prices\n",
        "- Compare baseline algorithms with cross-validation\n",
        "- Tune the best candidate model with GridSearchCV\n",
        "- Evaluate final model performance (learning curves, residuals)\n",
        "- Inspect feature importances (permutation and tree-based)\n",
        "- Generate predictions for Lydia’s four inherited houses\n",
        "\n",
        "\n",
        "## Inputs\n",
        "- outputs/datasets/engineered/TrainSetEngineered.csv\n",
        "- outputs/datasets/engineered/TestSetEngineered.csv\n",
        "- outputs/datasets/collection/InheritedHouses.csv\n",
        "\n",
        "## Outputs\n",
        "- Model comparison table (CV RMSE, R², MAE)\n",
        "- Final tuned pipeline saved to `outputs/ml_pipeline/predict_price/predict_price_pipeline_v1.pkl`\n",
        "- Feature importance plots under `docs/plots`\n",
        "- Learning and residual plots\n",
        "- Predicted sale prices for inherited homes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change Working Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "\n",
        "- We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory.\n",
        "\n",
        "- os.path.dirname() gets the parent directory\n",
        "- os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    GridSearchCV,\n",
        "    cross_val_score,\n",
        "    learning_curve,\n",
        "    validation_curve,\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# regressors to compare\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    AdaBoostRegressor,\n",
        "    ExtraTreesRegressor,\n",
        ")\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Load Engineered Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"outputs/datasets/engineered/TrainSetEngineered.csv\")\n",
        "test = pd.read_csv(\"outputs/datasets/engineered/TestSetEngineered.csv\")\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape: \", test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = \"SalePrice\"\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model Comparison with Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate multiple models with 5-fold CV on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesRegressor(random_state=42),\n",
        "    \"XGB\": XGBRegressor(random_state=42, use_label_encoder=False, eval_metric=\"rmse\"),\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])  # scale for LR\n",
        "    # 5-fold CV RMSE, R2, MAE\n",
        "    rmse_scores = -cross_val_score(\n",
        "        pipe, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1\n",
        "    )\n",
        "    r2_scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring=\"r2\", n_jobs=-1)\n",
        "    mae_scores = -cross_val_score(\n",
        "        pipe, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1\n",
        "    )\n",
        "    results.append(\n",
        "        {\n",
        "            \"Model\": name,\n",
        "            \"RMSE_Mean\": rmse_scores.mean(),\n",
        "            \"R2_Mean\": r2_scores.mean(),\n",
        "            \"MAE_Mean\": mae_scores.mean(),\n",
        "        }\n",
        "    )\n",
        "\n",
        "df_results = pd.DataFrame(results).sort_values(\"RMSE_Mean\")\n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Best Candidate & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    \"model__n_estimators\": [100, 200, 300],\n",
        "    \"model__max_depth\": [None, 10, 20],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "}\n",
        "\n",
        "best_name = df_results.iloc[0][\"Model\"]\n",
        "best_model = models[best_name]\n",
        "\n",
        "pipe = Pipeline([(\"model\", best_model)])\n",
        "grid = GridSearchCV(\n",
        "    pipe, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, verbose=1\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params for\", best_name, \":\", grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_performance(pipe, Xtr, ytr, Xte, yte):\n",
        "    \"\"\"\n",
        "    Print RMSE, R^2, MAE for train and test sets.\n",
        "    \"\"\"\n",
        "    preds_tr = pipe.predict(Xtr)\n",
        "    preds_te = pipe.predict(Xte)\n",
        "    for name, X, y, preds in [\n",
        "        (\"Train\", Xtr, ytr, preds_tr),\n",
        "        (\"Test\", Xte, yte, preds_te),\n",
        "    ]:\n",
        "        rmse = np.sqrt(mean_squared_error(y, preds))\n",
        "        r2 = r2_score(y, preds)\n",
        "        mae = mean_absolute_error(y, preds)\n",
        "        print(f\"{name} RMSE: {rmse:.2f}, R2: {r2:.3f}, MAE: {mae:.2f}\")\n",
        "\n",
        "\n",
        "final_pipe = grid.best_estimator_\n",
        "evaluate_performance(final_pipe, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    final_pipe,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"neg_root_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "    n_jobs=-1,\n",
        ")\n",
        "train_rmse = -train_scores\n",
        "test_rmse = -test_scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_sizes, train_rmse.mean(axis=1), \"o-\", label=\"Train RMSE\")\n",
        "plt.plot(train_sizes, test_rmse.mean(axis=1), \"o-\", label=\"CV RMSE\")\n",
        "plt.xlabel(\"Training Examples\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.legend()\n",
        "Path(\"docs/plots\").mkdir(parents=True, exist_ok=True)\n",
        "plt.savefig(\"docs/plots/learning_curve.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Residual Plot (Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residuals = y_test - final_pipe.predict(X_test)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title(\"Residual Distribution (Test)\")\n",
        "plt.xlabel(\"Residual\")\n",
        "plt.savefig(\"docs/plots/residuals.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare tree-based importances and permutation importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tree-based\n",
        "if hasattr(final_pipe.named_steps[\"model\"], \"feature_importances_\"):\n",
        "    feat_names = X_train.columns\n",
        "    tree_imp = final_pipe.named_steps[\"model\"].feature_importances_\n",
        "    df_tree = pd.Series(tree_imp, index=feat_names).sort_values(ascending=False)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x=df_tree.head(20).values, y=df_tree.head(20).index)\n",
        "    plt.title(\"Top 20 Tree-based Feature Importances\")\n",
        "    plt.savefig(\"docs/plots/feature_importances_tree.png\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    # Permutation\n",
        "    perm = permutation_importance(\n",
        "        final_pipe, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
        "    )\n",
        "    df_perm = pd.Series(perm.importances_mean, index=feat_names).sort_values(\n",
        "        ascending=False\n",
        "    )\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x=df_perm.head(20).values, y=df_perm.head(20).index)\n",
        "    plt.title(\"Top 20 Permutation Importances\")\n",
        "    plt.savefig(\"docs/plots/feature_importances_perm.png\", bbox_inches=\"tight\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Inherited Houses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inherited_path = Path(\"outputs/datasets/collection/InheritedHouses.csv\")\n",
        "inherited = pd.read_csv(inherited_path)\n",
        "# Ensure same columns and preprocessing\n",
        "preds_inh = final_pipe.predict(inherited)\n",
        "print(\"Predicted sale prices for inherited houses:\")\n",
        "for i, p in enumerate(preds_inh, 1):\n",
        "    print(f\"  House {i}: ${p:,.0f}\")\n",
        "print(f\"Total estimated value: ${preds_inh.sum():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Final Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_path = Path(\"outputs/ml_pipeline/predict_price/predict_price_pipeline_v1.pkl\")\n",
        "Path(output_path.parent).mkdir(parents=True, exist_ok=True)\n",
        "import joblib\n",
        "\n",
        "joblib.dump(final_pipe, output_path)\n",
        "print(f\"Saved final pipeline to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Summary and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Summary**:\n",
        "- Tuned **{best_name}** achieved Test RMSE and R² requirements.\n",
        "- Learning curves suggest {'overfitting' if test_rmse.mean()>train_rmse.mean() else 'good fit'}.\n",
        "- Key predictors include top features from permutation importances.\n",
        "\n",
        "**Next:** integrate `predict_price_pipeline_v1.pkl` into Streamlit app for deployment."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
